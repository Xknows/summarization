{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular such as by writing grammars or devising heuristic rules for stemming.\n",
        "Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach:\n",
        "both statistical and neural networks methods can focus more on the most common cases extracted from a corpus of texts, whereas the rule-based approach needs to provide rules for both rare cases and common ones equally.\n",
        "language models, produced by either statistical or neural networks methods, are more robust to both unfamiliar (e.g. containing words or structures that have not been seen before) and erroneous input (e.g. with misspelled words or words accidentally omitted) in comparison to the rule-based systems, which are also more costly to produce.\n",
        "the larger such a (probabilistic) language model is, the more accurate it becomes, in contrast to rule-based systems that can gain accuracy only by increasing the amount and complexity of the rules leading to intractability problems.\n",
        "Although rule-based systems for manipulating symbols were still in use in 2020, they have become mostly obsolete with the advance of LLMs in 2023.\n",
        "Before that they were commonly used: when the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the Apertium system, for preprocessing in NLP pipelines, e.g., tokenization, or for postprocessing and transforming the output of NLP pipelines, e.g., for knowledge extraction from syntactic parses.\"\"\""
      ],
      "metadata": {
        "id": "z5Ckos-vqJ30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"\"\"Johannes Gutenberg (1398 – 1468) was a German goldsmith and publisher who introduced printing to Europe. His introduction of mechanical movable type printing to Europe started the Printing Revolution and is widely regarded as the most important event of the modern period. It played a key role in the scientific revolution and laid the basis for the modern knowledge-based economy and the spread of learning to the masses.“Alice’s Adventures in the Wonderland” is a very popular book for children that adults can also enjoy reading. The author is Charles Dodson, an English writer who published the book in 1865 under the pseudonym of Lewis Carroll.Through its fantasy story and main theme: “a growing girl exploring the wonders of world“, the book has been very influential over the years, both in popular culture and in literature. The book is an enigmatic work, and over the years, readers have been puzzled by the language and the logic of Wonderland.The protagonist of the book is Alice, a seven years old girl who must find her way in a strange world called “Wonderland”. During her magic journey through Wonderland, Alice encounters peculiar human-like creatures or talking animals: the White Rabbit, the Caterpillar, the Cheshire Cat, the Mad Hatter, and the Dormouse.The White Rabbit is Alice’s guide and he leads her on many places and adventures through the book. The always hurrying rabbit is a symbol of forever running timeThe smiling Cheshire Cat, who can disappear and reappear, is the only character in the entire novel who listens to Alice. The Cat is giving “advice” to Alice and teaches her the strange rules leading the world she is traveling through.The Cheshire-Cat’s smile is a metaphor of Wonderland’s magic and it is as famous and enigmatic as Mona Lisa’s smile.Each character teaches Alice something about life and growing up in a hazardous world. Every object or setting in “Alice in the Wonderland” functions as a symbol and often the symbols work together to convey a particular meaning to a scene.Through an intricate symbolism, Lewis Carroll suggests the complexity of life.This could be the message learned by Alice in her magic, initiatory journey: don’t try to find meaning in all the situations you encounter in the “wonder” world of life, don’t give up and continue your way.\"\"\""
      ],
      "metadata": {
        "id": "kUh-nYLqP-Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piWTWeR9qAN3",
        "outputId": "3aee2fd4-2580-4789-ec53-7f36c6ad5c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1777"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation as str_punc"
      ],
      "metadata": {
        "id": "sqnduD1MAvdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = list(STOP_WORDS)"
      ],
      "metadata": {
        "id": "ueTIwCsHDbnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB013EXIWdvu",
        "outputId": "c263da48-3910-437b-d343-2281879093bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-29 11:15:59.571093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "y0IxPgSCAvgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "Ee1B_zYFAvil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token.text for token in doc]"
      ],
      "metadata": {
        "id": "iGTYtdJ1Avlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequency = {}\n",
        "for word in doc:\n",
        "  if word.text.lower() not in stop_words:\n",
        "    if word.text.lower() not in str_punc:\n",
        "      if word.text not in word_frequency.keys():\n",
        "        word_frequency[word.text] = 1\n",
        "      else:\n",
        "        word_frequency[word.text] += 1\n"
      ],
      "metadata": {
        "id": "DLaGQLc7BRHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequency = max(word_frequency.values())"
      ],
      "metadata": {
        "id": "5flbf05uAvn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_frequency.keys():\n",
        "  word_frequency[word] = word_frequency[word]/max_frequency"
      ],
      "metadata": {
        "id": "zomAnb8rAvp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_frequency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fYrw0g2Avrv",
        "outputId": "ff7c411e-6f47-45c2-c1de-42f2f14a9990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Symbolic': 0.16666666666666666, 'approach': 0.6666666666666666, 'i.e.': 0.16666666666666666, 'hand': 0.3333333333333333, 'coding': 0.16666666666666666, 'set': 0.16666666666666666, 'rules': 0.6666666666666666, 'manipulating': 0.3333333333333333, 'symbols': 0.3333333333333333, 'coupled': 0.16666666666666666, 'dictionary': 0.16666666666666666, 'lookup': 0.16666666666666666, 'historically': 0.16666666666666666, 'AI': 0.16666666666666666, 'general': 0.16666666666666666, 'NLP': 0.5, 'particular': 0.16666666666666666, 'writing': 0.16666666666666666, 'grammars': 0.16666666666666666, 'devising': 0.16666666666666666, 'heuristic': 0.16666666666666666, 'stemming': 0.16666666666666666, '\\n': 1.0, 'Machine': 0.16666666666666666, 'learning': 0.3333333333333333, 'approaches': 0.16666666666666666, 'include': 0.16666666666666666, 'statistical': 0.5, 'neural': 0.5, 'networks': 0.5, 'advantages': 0.16666666666666666, 'symbolic': 0.16666666666666666, 'methods': 0.5, 'focus': 0.16666666666666666, 'common': 0.3333333333333333, 'cases': 0.3333333333333333, 'extracted': 0.16666666666666666, 'corpus': 0.16666666666666666, 'texts': 0.16666666666666666, 'rule': 0.6666666666666666, 'based': 0.6666666666666666, 'needs': 0.16666666666666666, 'provide': 0.16666666666666666, 'rare': 0.16666666666666666, 'ones': 0.16666666666666666, 'equally': 0.16666666666666666, 'language': 0.3333333333333333, 'models': 0.16666666666666666, 'produced': 0.16666666666666666, 'robust': 0.16666666666666666, 'unfamiliar': 0.16666666666666666, 'e.g.': 0.8333333333333334, 'containing': 0.16666666666666666, 'words': 0.5, 'structures': 0.16666666666666666, 'seen': 0.16666666666666666, 'erroneous': 0.16666666666666666, 'input': 0.16666666666666666, 'misspelled': 0.16666666666666666, 'accidentally': 0.16666666666666666, 'omitted': 0.16666666666666666, 'comparison': 0.16666666666666666, 'systems': 0.5, 'costly': 0.16666666666666666, 'produce': 0.16666666666666666, 'larger': 0.16666666666666666, 'probabilistic': 0.16666666666666666, 'model': 0.16666666666666666, 'accurate': 0.16666666666666666, 'contrast': 0.16666666666666666, 'gain': 0.16666666666666666, 'accuracy': 0.16666666666666666, 'increasing': 0.16666666666666666, 'complexity': 0.16666666666666666, 'leading': 0.16666666666666666, 'intractability': 0.16666666666666666, 'problems': 0.16666666666666666, 'use': 0.16666666666666666, '2020': 0.16666666666666666, 'obsolete': 0.16666666666666666, 'advance': 0.16666666666666666, 'LLMs': 0.16666666666666666, '2023': 0.16666666666666666, 'commonly': 0.16666666666666666, 'training': 0.16666666666666666, 'data': 0.16666666666666666, 'insufficient': 0.16666666666666666, 'successfully': 0.16666666666666666, 'apply': 0.16666666666666666, 'machine': 0.3333333333333333, 'translation': 0.16666666666666666, 'low': 0.16666666666666666, 'resource': 0.16666666666666666, 'languages': 0.16666666666666666, 'provided': 0.16666666666666666, 'Apertium': 0.16666666666666666, 'system': 0.16666666666666666, 'preprocessing': 0.16666666666666666, 'pipelines': 0.3333333333333333, 'tokenization': 0.16666666666666666, 'postprocessing': 0.16666666666666666, 'transforming': 0.16666666666666666, 'output': 0.16666666666666666, 'knowledge': 0.16666666666666666, 'extraction': 0.16666666666666666, 'syntactic': 0.16666666666666666, 'parses': 0.16666666666666666}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = [sentence for sentence in doc.sents]\n",
        "print(sentence_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utMIqvFGMmKc",
        "outputId": "82243684-4845-45be-b2b7-8b622c1049c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular such as by writing grammars or devising heuristic rules for stemming.\n",
            ", Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach:\n",
            "both statistical and neural networks methods can focus more on the most common cases extracted from a corpus of texts, whereas the rule-based approach needs to provide rules for both rare cases and common ones equally.\n",
            "language models, produced by either statistical or neural networks methods, are more robust to both unfamiliar (e.g. containing words or structures that have not been seen before) and erroneous input (e.g. with misspelled words or words accidentally omitted) in comparison to the rule-based systems, which are also more costly to produce.\n",
            ", the larger such a (probabilistic) language model is, the more accurate it becomes, in contrast to rule-based systems that can gain accuracy only by increasing the amount and complexity of the rules leading to intractability problems.\n",
            ", Although rule-based systems for manipulating symbols were still in use in 2020, they have become mostly obsolete with the advance of LLMs in 2023.\n",
            ", Before that they were commonly used: when the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the Apertium system, for preprocessing in NLP pipelines, e.g., tokenization, or for postprocessing and transforming the output of NLP pipelines, e.g., for knowledge extraction from syntactic parses.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_score = {}\n",
        "for sentence in sentence_tokens:\n",
        "  for word in sentence:\n",
        "    if word.text.lower( ) in word_frequency.keys():\n",
        "      if sentence not in sentence_score.keys():\n",
        "        sentence_score[sentence] = word_frequency[word.text.lower()]\n",
        "      else:\n",
        "        sentence_score[sentence] += word_frequency[word.text.lower()]"
      ],
      "metadata": {
        "id": "LjXGooilKUPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrqCJI1rKUSf",
        "outputId": "b5ecca06-0034-4e5d-a9f7-84b080d27bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular such as by writing grammars or devising heuristic rules for stemming.\n",
            ": 7.166666666666669, Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach:\n",
            "both statistical and neural networks methods can focus more on the most common cases extracted from a corpus of texts, whereas the rule-based approach needs to provide rules for both rare cases and common ones equally.\n",
            "language models, produced by either statistical or neural networks methods, are more robust to both unfamiliar (e.g. containing words or structures that have not been seen before) and erroneous input (e.g. with misspelled words or words accidentally omitted) in comparison to the rule-based systems, which are also more costly to produce.\n",
            ": 24.166666666666675, the larger such a (probabilistic) language model is, the more accurate it becomes, in contrast to rule-based systems that can gain accuracy only by increasing the amount and complexity of the rules leading to intractability problems.\n",
            ": 5.833333333333333, Although rule-based systems for manipulating symbols were still in use in 2020, they have become mostly obsolete with the advance of LLMs in 2023.\n",
            ": 4.333333333333332, Before that they were commonly used: when the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the Apertium system, for preprocessing in NLP pipelines, e.g., tokenization, or for postprocessing and transforming the output of NLP pipelines, e.g., for knowledge extraction from syntactic parses.: 8.166666666666666}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from heapq import nlargest                 # Heap queue algorithm"
      ],
      "metadata": {
        "id": "dwyuOeZiAvuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentence_score)  * 0.2                 # select 20 percent of high score sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O6HmNjdNA3U",
        "outputId": "092d18fe-80b9-44f7-c466-8f1719a21253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = nlargest(n = 1, iterable = sentence_score, key = sentence_score.get)\n"
      ],
      "metadata": {
        "id": "8p7UXAXDNA52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_summary = [word.text for word in summary]"
      ],
      "metadata": {
        "id": "F-FJKVhaNA8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_summary = \"\".join(final_summary)"
      ],
      "metadata": {
        "id": "ynLr2OWLPZjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH4Qoo3RPZrS",
        "outputId": "fd06ee5f-299d-41c4-b1dd-c0fe25fcb1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach:\n",
            "both statistical and neural networks methods can focus more on the most common cases extracted from a corpus of texts, whereas the rule-based approach needs to provide rules for both rare cases and common ones equally.\n",
            "language models, produced by either statistical or neural networks methods, are more robust to both unfamiliar (e.g. containing words or structures that have not been seen before) and erroneous input (e.g. with misspelled words or words accidentally omitted) in comparison to the rule-based systems, which are also more costly to produce.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHd5BvoFOywa",
        "outputId": "676f6044-1c4d-4b2d-f292-54e0c87e6a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "707"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}